{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "OrOiwn27576x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrOiwn27576x",
        "outputId": "a57fc907-85e7-4634-d231-e149e310fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "yLYPxeaKZWUr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLYPxeaKZWUr",
        "outputId": "49196328-33c6-4b80-c2c8-b0f74386ebc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/실용적딥러닝/buildings.zip\n",
            "   creating: /content/buildings/\n",
            "  inflating: /content/__MACOSX/._buildings  \n",
            "  inflating: /content/buildings/.DS_Store  \n",
            "  inflating: /content/__MACOSX/buildings/._.DS_Store  \n",
            "   creating: /content/buildings/train_images/\n",
            "   creating: /content/buildings/train_masks/\n",
            "  inflating: /content/buildings/train_images/48.png  \n",
            "  inflating: /content/buildings/train_images/49.png  \n",
            "  inflating: /content/buildings/train_images/8.png  \n",
            "  inflating: /content/buildings/train_images/9.png  \n",
            "  inflating: /content/buildings/train_images/28.png  \n",
            "  inflating: /content/buildings/train_images/15.png  \n",
            "  inflating: /content/buildings/train_images/17.png  \n",
            "  inflating: /content/buildings/train_images/39.png  \n",
            "  inflating: /content/buildings/train_images/11.png  \n",
            "  inflating: /content/buildings/train_images/10.png  \n",
            "  inflating: /content/buildings/train_images/38.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_images/._38.png  \n",
            "  inflating: /content/buildings/train_images/35.png  \n",
            "  inflating: /content/buildings/train_images/34.png  \n",
            "  inflating: /content/buildings/train_images/22.png  \n",
            "  inflating: /content/buildings/train_images/36.png  \n",
            "  inflating: /content/buildings/train_images/37.png  \n",
            "  inflating: /content/buildings/train_images/23.png  \n",
            "  inflating: /content/buildings/train_images/27.png  \n",
            "  inflating: /content/buildings/train_images/33.png  \n",
            "  inflating: /content/buildings/train_images/32.png  \n",
            "  inflating: /content/buildings/train_images/18.png  \n",
            "  inflating: /content/buildings/train_images/30.png  \n",
            "  inflating: /content/buildings/train_images/31.png  \n",
            "  inflating: /content/buildings/train_images/4.png  \n",
            "  inflating: /content/buildings/train_images/42.png  \n",
            "  inflating: /content/buildings/train_images/43.png  \n",
            "  inflating: /content/buildings/train_images/5.png  \n",
            "  inflating: /content/buildings/train_images/41.png  \n",
            "  inflating: /content/buildings/train_images/7.png  \n",
            "  inflating: /content/buildings/train_images/6.png  \n",
            "  inflating: /content/buildings/train_images/40.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_images/._40.png  \n",
            "  inflating: /content/buildings/train_images/44.png  \n",
            "  inflating: /content/buildings/train_images/2.png  \n",
            "  inflating: /content/buildings/train_images/50.png  \n",
            "  inflating: /content/buildings/train_images/51.png  \n",
            "  inflating: /content/buildings/train_images/45.png  \n",
            "  inflating: /content/buildings/train_images/1.png  \n",
            "  inflating: /content/buildings/train_images/47.png  \n",
            "  inflating: /content/buildings/train_images/46.png  \n",
            "  inflating: /content/buildings/train_images/0.png  \n",
            "  inflating: /content/buildings/train_masks/48.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._48.png  \n",
            "  inflating: /content/buildings/train_masks/49.png  \n",
            "  inflating: /content/buildings/train_masks/8.png  \n",
            "  inflating: /content/buildings/train_masks/9.png  \n",
            "  inflating: /content/buildings/train_masks/28.png  \n",
            "  inflating: /content/buildings/train_masks/15.png  \n",
            "  inflating: /content/buildings/train_masks/17.png  \n",
            "  inflating: /content/buildings/train_masks/39.png  \n",
            "  inflating: /content/buildings/train_masks/11.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._11.png  \n",
            "  inflating: /content/buildings/train_masks/10.png  \n",
            "  inflating: /content/buildings/train_masks/38.png  \n",
            "  inflating: /content/buildings/train_masks/35.png  \n",
            "  inflating: /content/buildings/train_masks/34.png  \n",
            "  inflating: /content/buildings/train_masks/22.png  \n",
            "  inflating: /content/buildings/train_masks/36.png  \n",
            "  inflating: /content/buildings/train_masks/37.png  \n",
            "  inflating: /content/buildings/train_masks/23.png  \n",
            "  inflating: /content/buildings/train_masks/27.png  \n",
            "  inflating: /content/buildings/train_masks/33.png  \n",
            "  inflating: /content/buildings/train_masks/32.png  \n",
            "  inflating: /content/buildings/train_masks/18.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._18.png  \n",
            "  inflating: /content/buildings/train_masks/30.png  \n",
            "  inflating: /content/buildings/train_masks/31.png  \n",
            "  inflating: /content/buildings/train_masks/4.png  \n",
            "  inflating: /content/buildings/train_masks/42.png  \n",
            "  inflating: /content/buildings/train_masks/43.png  \n",
            "  inflating: /content/buildings/train_masks/5.png  \n",
            "  inflating: /content/buildings/train_masks/41.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._41.png  \n",
            "  inflating: /content/buildings/train_masks/7.png  \n",
            "  inflating: /content/buildings/train_masks/6.png  \n",
            "  inflating: /content/buildings/train_masks/40.png  \n",
            "  inflating: /content/buildings/train_masks/44.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._44.png  \n",
            "  inflating: /content/buildings/train_masks/2.png  \n",
            "  inflating: /content/buildings/train_masks/50.png  \n",
            "  inflating: /content/buildings/train_masks/51.png  \n",
            "  inflating: /content/__MACOSX/buildings/train_masks/._51.png  \n",
            "  inflating: /content/buildings/train_masks/45.png  \n",
            "  inflating: /content/buildings/train_masks/1.png  \n",
            "  inflating: /content/buildings/train_masks/47.png  \n",
            "  inflating: /content/buildings/train_masks/46.png  \n",
            "  inflating: /content/buildings/train_masks/0.png  \n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/실용적딥러닝/buildings.zip\" -d \"/content/\"\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "l-SNalf29KQZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-SNalf29KQZ",
        "outputId": "cba5b889-2f93-4a1f-b701-c5293a1714ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "XI28K-TYV759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI28K-TYV759",
        "outputId": "dfa0cc06-144d-4a1d-aeb6-8ffa1945495c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.4)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=08f596c8bd473c359c44ac76c19752d7eafb9992d2e60f692745841b8dc452c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=17418ad9cb0d8a45a62dde90a10a82e2dbe00f60adbc718a7dacbeabd58a9065\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision segmentation-models-pytorch albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "iTbMifkCXS95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTbMifkCXS95",
        "outputId": "651d78dc-7ba9-4237-9474-cb7ba3eb5148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.11.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "WfOXUCH2XXLL",
      "metadata": {
        "id": "WfOXUCH2XXLL"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "o85NklqGVyAw",
      "metadata": {
        "id": "o85NklqGVyAw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "TQHNGEu_V5-w",
      "metadata": {
        "id": "TQHNGEu_V5-w"
      },
      "outputs": [],
      "source": [
        "class BuildingsDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, transform=None, patch_size=256, stride=256):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.images = os.listdir(images_dir)\n",
        "        self.transform = transform\n",
        "        self.patch_size = patch_size\n",
        "        self.stride = stride\n",
        "        self.image_patches = []\n",
        "        self.mask_patches = []\n",
        "\n",
        "        for image_name in self.images:\n",
        "            img_path = os.path.join(self.images_dir, image_name)\n",
        "            mask_path = os.path.join(self.masks_dir, image_name.replace('.jpg', '.png'))\n",
        "            image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "            mask = np.array(Image.open(mask_path), dtype=np.float32)\n",
        "            mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "            img_patches, mask_patches = self.crop_to_patches(image, mask, self.patch_size, self.stride)\n",
        "            self.image_patches.extend(img_patches)\n",
        "            self.mask_patches.extend(mask_patches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_patches[idx]\n",
        "        mask = self.mask_patches[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def crop_to_patches(self, image, mask, patch_size, stride):\n",
        "        patches_img = []\n",
        "        patches_mask = []\n",
        "        img_height, img_width = image.shape[:2]\n",
        "        for y in range(0, img_height, stride):\n",
        "            for x in range(0, img_width, stride):\n",
        "                patch_img = image[y:y+patch_size, x:x+patch_size]\n",
        "                patch_mask = mask[y:y+patch_size, x:x+patch_size]\n",
        "                if patch_img.shape[0] == patch_size and patch_img.shape[1] == patch_size:\n",
        "                    patches_img.append(patch_img)\n",
        "                    patches_mask.append(patch_mask)\n",
        "        return patches_img, patches_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "D5okFLw7WP5o",
      "metadata": {
        "id": "D5okFLw7WP5o"
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = A.Compose([\n",
        "        # A.HorizontalFlip(p=0.5),\n",
        "        # A.VerticalFlip(p=0.5),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "    return train_transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "0lANQMxXehup",
      "metadata": {
        "id": "0lANQMxXehup"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "IRGn5MsXedbM",
      "metadata": {
        "id": "IRGn5MsXedbM"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        # flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ONRkyS-AZfJD",
      "metadata": {
        "id": "ONRkyS-AZfJD"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "dataset = BuildingsDataset(\n",
        "    images_dir='buildings/train_images',\n",
        "    masks_dir='buildings/train_masks',\n",
        "    transform=get_training_augmentation()\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "0qWavc7xcLY2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qWavc7xcLY2",
        "outputId": "5609282a-47a6-4d09-8d4f-c90a029c8d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1960\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "74A5Inope75j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74A5Inope75j",
        "outputId": "f81c041e-1606-4dcb-ef78-ffb015a0ee54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "\n",
        "resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Helper module that consists of a Conv -> BN -> ReLU\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.with_nonlinearity = with_nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.with_nonlinearity:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Bridge(nn.Module):\n",
        "    \"\"\"\n",
        "    This is the middle layer of the UNet which just consists of some\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.bridge = nn.Sequential(\n",
        "            ConvBlock(in_channels, out_channels),\n",
        "            ConvBlock(out_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bridge(x)\n",
        "\n",
        "\n",
        "class UpBlockForUNetWithResNet50(nn.Module):\n",
        "    \"\"\"\n",
        "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
        "                 upsampling_method=\"conv_transpose\"):\n",
        "        super().__init__()\n",
        "\n",
        "        if up_conv_in_channels == None:\n",
        "            up_conv_in_channels = in_channels\n",
        "        if up_conv_out_channels == None:\n",
        "            up_conv_out_channels = out_channels\n",
        "\n",
        "        if upsampling_method == \"conv_transpose\":\n",
        "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
        "        elif upsampling_method == \"bilinear\":\n",
        "            self.upsample = nn.Sequential(\n",
        "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "            )\n",
        "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
        "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
        "\n",
        "    def forward(self, up_x, down_x):\n",
        "        \"\"\"\n",
        "\n",
        "        :param up_x: this is the output from the previous up block\n",
        "        :param down_x: this is the output from the down block\n",
        "        :return: upsampled feature map\n",
        "        \"\"\"\n",
        "        x = self.upsample(up_x)\n",
        "        x = torch.cat([x, down_x], 1)\n",
        "        x = self.conv_block_1(x)\n",
        "        x = self.conv_block_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNetWithResnet50Encoder(nn.Module):\n",
        "    DEPTH = 6\n",
        "\n",
        "    def __init__(self, n_classes=1):\n",
        "        super().__init__()\n",
        "        resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
        "        down_blocks = []\n",
        "        up_blocks = []\n",
        "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
        "        self.input_pool = list(resnet.children())[3]\n",
        "        for bottleneck in list(resnet.children()):\n",
        "            if isinstance(bottleneck, nn.Sequential):\n",
        "                down_blocks.append(bottleneck)\n",
        "        self.down_blocks = nn.ModuleList(down_blocks)\n",
        "        self.bridge = Bridge(2048, 2048)\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
        "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
        "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
        "\n",
        "        self.up_blocks = nn.ModuleList(up_blocks)\n",
        "\n",
        "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x, with_output_feature_map=False):\n",
        "        pre_pools = dict()\n",
        "        pre_pools[f\"layer_0\"] = x\n",
        "        x = self.input_block(x)\n",
        "        pre_pools[f\"layer_1\"] = x\n",
        "        x = self.input_pool(x)\n",
        "\n",
        "        for i, block in enumerate(self.down_blocks, 2):\n",
        "            x = block(x)\n",
        "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
        "                continue\n",
        "            pre_pools[f\"layer_{i}\"] = x\n",
        "\n",
        "        x = self.bridge(x)\n",
        "\n",
        "        for i, block in enumerate(self.up_blocks, 1):\n",
        "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
        "            x = block(x, pre_pools[key])\n",
        "        output_feature_map = x\n",
        "        x = self.out(x)\n",
        "        del pre_pools\n",
        "        if with_output_feature_map:\n",
        "            return x, output_feature_map\n",
        "        else:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "awBeTE8seyDj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awBeTE8seyDj",
        "outputId": "c15af6a5-c8a8-40b8-c3bc-81906267dc05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 1, Loss: 0.18984179342946694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 2, Loss: 0.06973429841379963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 3, Loss: 0.059140268833406506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 4, Loss: 0.04434964926012097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 5, Loss: 0.0377617132279181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 6, Loss: 0.035733061452065784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 7, Loss: 0.03469276812768751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 8, Loss: 0.03396014436598749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 9, Loss: 0.03240152135972052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:53<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch 10, Loss: 0.033913625824836036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "# 하이퍼파라미터\n",
        "epoch_num = 10\n",
        "learning_rate = 0.001\n",
        "patience = 4\n",
        "early_stopping_counter = 0  # Early stopping counter\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# model 초기화\n",
        "model = UNetWithResnet50Encoder().to(device)\n",
        "\n",
        "# loss function과 optimizer 정의\n",
        "criterion = DiceLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience)\n",
        "\n",
        "\n",
        "# training loop\n",
        "for epoch in range(epoch_num):  # 30 에폭 동안 학습합니다.\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in tqdm(dataloader):\n",
        "        images = images.float().to(device)\n",
        "        masks = masks.float().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f'Train Epoch {epoch+1}, Loss: {1+epoch_loss/len(dataloader)}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
        "be76a29e-e9c2-411a-a569-04166f074184",
        "msoipHkb9WNF",
        "a0895765-fba0-4fd9-b955-a6c0e43012e9",
        "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
        "36c2cbbb-04f1-4f9c-b4df-4b744dfce046"
      ],
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
